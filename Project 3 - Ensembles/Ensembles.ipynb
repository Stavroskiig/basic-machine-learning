{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8gU7AYPXMmA"
   },
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    " **What you need to remember:**\n",
    "\n",
    "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
    "- Write code in the designated areas using Python 3 only\n",
    "- Do not modify the code outside of the designated areas\n",
    "- In some cases you will also need to explain the results. There will also be designated areas for that.\n",
    "\n",
    "Fill in your **NAME** and **AEM** below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lO-jJrtNXMmH"
   },
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "AEM = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sh0EE7BJXMmJ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_VpnGyWXMmK"
   },
   "source": [
    "# Assignment 3 - Ensemble Methods #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dQ9XoGQXMmK"
   },
   "source": [
    "Welcome to your third assignment. This exercise will test your understanding on Ensemble Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JvHYIhS-XMmL"
   },
   "outputs": [],
   "source": [
    "# Always run this cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# USE THE FOLLOWING RANDOM STATE FOR YOUR CODE\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joKwpih2XMmM"
   },
   "source": [
    "## Download the Dataset ##\n",
    "Download the dataset using the following cell or from this [link](https://github.com/sakrifor/public/tree/master/machine_learning_course/EnsembleDataset) and put the files in the same folder as the .ipynb file.\n",
    "In this assignment you are going to work with a dataset originated from the [ImageCLEFmed: The Medical Task 2016](https://www.imageclef.org/2016/medical) and the **Compound figure detection** subtask. The goal of this subtask is to identify whether a figure is a compound figure (one image consists of more than one figure) or not. The train dataset consits of 4197 examples/figures and each figure has 4096 features which were extracted using a deep neural network. The *CLASS* column represents the class of each example where 1 is a compoung figure and 0 is not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJdwPr0bXMmM",
    "outputId": "189b3b69-429e-44ad-a927-9caabad50389"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('test_set_noclass.csv', <http.client.HTTPMessage at 0x7f52c1c681c0>)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import urllib.request\n",
    "url_train = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/train_set.csv'\n",
    "filename_train = 'train_set.csv'\n",
    "urllib.request.urlretrieve(url_train, filename_train)\n",
    "url_test = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/test_set_noclass.csv'\n",
    "filename_test = 'test_set_noclass.csv'\n",
    "urllib.request.urlretrieve(url_test, filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "t0OVtYr7XMmN"
   },
   "outputs": [],
   "source": [
    "# Run this cell to load the data\n",
    "train_set = pd.read_csv(\"train_set.csv\").sample(frac=1).reset_index(drop=True)\n",
    "train_set.head()\n",
    "X = train_set.drop(columns=['CLASS'])\n",
    "y = train_set['CLASS'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4XK751YSecqQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d55b794b-d208-4a02-998d-d714d9238d89"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQH40Vb5fvx2"
   },
   "source": [
    "The following code will reduce the number of instances, dealing with the small imbalance of the dataset, as well as reducing the size of the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIgD6Nmkeaxv",
    "outputId": "41969b6f-2c23-408e-fb74-ac72dd40e12c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Resampled dataset shape Counter({0: 1687, 1: 1687})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule, RandomUnderSampler\n",
    "\n",
    "ncr = NeighbourhoodCleaningRule()\n",
    "X_res, y_res = ncr.fit_resample(X, y)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_res, y_res)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "X = X_res\n",
    "y = y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxOGHSmqXMmO"
   },
   "source": [
    "## 1.0 Testing different ensemble methods ##\n",
    "In this part of the assignment you are asked to create and test different ensemble methods using the train_set.csv dataset. You should use **5-fold cross validation** for your tests and report the average f-measure weighted and balanced accuracy of your models. You can use [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) and select both metrics to be measured during the evaluation.\n",
    "\n",
    "### !!! Use n_jobs=-1 where is posibble to use all the cores of a machine for running your tests ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ww_u4OlrXMmO"
   },
   "source": [
    "### 1.1 Voting ###\n",
    "Create a voting classifier which uses two **simple** estimators/classifiers. Test both soft and hard voting and report the results. Consider as simple estimators the following:\n",
    "\n",
    "\n",
    "*   Decision Trees\n",
    "*   Linear Models\n",
    "*   KNN Models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9xKWBVWVz3yV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bce61b6e-bfd2-46a4-8d2b-37adeb9b3d5a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classifier:\n",
      "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=42)),\n",
      "                             ('lr', LogisticRegression(random_state=42))],\n",
      "                 n_jobs=-1, voting='soft')\n",
      "F1 Weighted-Score: 0.7483 & Balanced Accuracy: 0.7484\n",
      "Classifier:\n",
      "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=42)),\n",
      "                             ('lr', LogisticRegression(random_state=42))],\n",
      "                 n_jobs=-1)\n",
      "F1 Weighted-Score: 0.816 & Balanced Accuracy: 0.8192\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "# USE RANDOM STATE!\n",
    "cls1 = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "cls2 = LogisticRegression(random_state=RANDOM_STATE)\n",
    "#cls3 = KNeighborsClassifier()\n",
    "\n",
    "# Use 2 classifiers\n",
    "soft_vcls = VotingClassifier(estimators=[('dt', cls1), ('lr', cls2)], voting='soft', n_jobs=-1)\n",
    "hard_vcls = VotingClassifier(estimators=[('dt', cls1), ('lr', cls2)], voting='hard', n_jobs=-1)\n",
    "\n",
    "# Use 3 classifiers\n",
    "#soft_vcls = VotingClassifier(estimators=[('dt', cls1), ('lr', cls2), ('knn', cls3)], voting='soft', n_jobs=-1)\n",
    "#hard_vcls = VotingClassifier(estimators=[('dt', cls1), ('lr', cls2), ('knn', cls3)], voting='hard', n_jobs=-1)\n",
    "\n",
    "scoring = ['f1_weighted', 'balanced_accuracy']\n",
    "#scoring = {'balanced_accuracy': make_scorer(balanced_accuracy_score),'f1_weighted': make_scorer(f1_score)}\n",
    "\n",
    "#kfold = KFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)\n",
    "\n",
    "svlcs_scores = cross_validate(soft_vcls, X, y, cv=5, scoring=scoring, n_jobs=-1)\n",
    "s_avg_fmeasure = np.mean(svlcs_scores['test_f1_weighted'])\n",
    "s_avg_accuracy = np.mean(svlcs_scores['test_balanced_accuracy'])\n",
    "\n",
    "hvlcs_scores = cross_validate(hard_vcls, X, y, cv=5, scoring=scoring, n_jobs=-1)\n",
    "h_avg_fmeasure = np.mean(hvlcs_scores['test_f1_weighted'])\n",
    "h_avg_accuracy = np.mean(hvlcs_scores['test_balanced_accuracy'])\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Classifier:\")\n",
    "print(soft_vcls)\n",
    "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(s_avg_fmeasure,4), round(s_avg_accuracy,4)))\n",
    "\n",
    "print(\"Classifier:\")\n",
    "print(hard_vcls)\n",
    "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(h_avg_fmeasure,4), round(h_avg_accuracy,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92ubbtE8gtHy"
   },
   "source": [
    "For both soft/hard voting classifiers the F1 weighted score should be above 0.74 and 0.79, respectively, and for balanced accuracy 0.74 and 0.80. Remember! This should be the average performance of each fold, as measured through cross-validation with 5 folds!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPG8MdFLXMmV"
   },
   "source": [
    "### 1.2 Randomization\n",
    "\n",
    "You are asked to create three ensembles of decision trees where each one uses a different method for producing homogeneous ensembles. Compare them with a simple decision tree classifier and report your results in the dictionaries (dict) below using as key the given name of your classifier and as value the f1_weighted/balanced_accuracy score. The dictionaries should contain four different elements. Use the same cross-validation approach as before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PmkaP-DjXMmV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fccb2017-2357-4583-de6e-b503aa9f1646"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 10.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 10.9min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  9.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  9.9min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=12),\n",
      "                  max_features=0.8, n_estimators=100, n_jobs=-1,\n",
      "                  random_state=42)\n",
      "RandomForestClassifier(max_depth=10, max_features='auto', n_estimators=500,\n",
      "                       n_jobs=-1, random_state=42)\n",
      "GradientBoostingClassifier(max_depth=5, random_state=42)\n",
      "DecisionTreeClassifier(max_depth=7, min_samples_leaf=2, random_state=42)\n",
      "Classifier: Bagging -  F1 Weighted: 0.8606\n",
      "Classifier: RandomForest -  F1 Weighted: 0.8549\n",
      "Classifier: GradientBoost -  F1 Weighted: 0.8741\n",
      "Classifier: DecisionTree -  F1 Weighted: 0.7534\n",
      "Classifier: Bagging -  BalancedAccuracy: 0.8583\n",
      "Classifier: RandomForest -  BalancedAccuracy: 0.8524\n",
      "Classifier: GradientBoost -  BalancedAccuracy: 0.874\n",
      "Classifier: DecisionTree -  BalancedAccuracy: 0.7584\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.4s finished\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "ens1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=12), max_features=0.8, n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "ens2 = RandomForestClassifier(criterion='gini', max_depth=10, max_features='auto', n_estimators=500,random_state=RANDOM_STATE, n_jobs=-1)\n",
    "ens3 = GradientBoostingClassifier(learning_rate=0.1, max_depth=5, n_estimators=100, random_state=RANDOM_STATE)\n",
    "#ens3 = ExtraTreesClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "tree = DecisionTreeClassifier(criterion='gini',max_depth=7, min_samples_leaf=2,splitter='best', random_state=RANDOM_STATE)\n",
    "\n",
    "f_measures = dict()\n",
    "accuracies = dict()\n",
    "# Example f_measures = {'Simple Decision': 0.8551, 'Ensemble with random ...': 0.92, ...}\n",
    "\n",
    "# A couple of functions to help us\n",
    "def evaluation(model, X, y):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_validate(model, X, y, scoring=('accuracy', 'f1'), cv=cv, verbose=2, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def scoring(model, X, y):\n",
    "    scores = evaluation(model, X, y)\n",
    "    f1_score = np.mean(scores['test_f1'])\n",
    "    acc_score = np.mean(scores['test_accuracy'])\n",
    "    return f1_score, acc_score\n",
    "\n",
    "f1_ens1, acc_ens1 = scoring(ens1, X, y)\n",
    "f1_ens2, acc_ens2 = scoring(ens2, X, y)\n",
    "f1_ens3, acc_ens3 = scoring(ens3, X, y)\n",
    "f1_tree, acc_tree = scoring(tree, X, y)\n",
    "\n",
    "f_measures['Bagging'] = f1_ens1\n",
    "f_measures['RandomForest'] = f1_ens2\n",
    "f_measures['GradientBoost'] = f1_ens3\n",
    "f_measures['DecisionTree'] = f1_tree\n",
    "\n",
    "accuracies['Bagging'] = acc_ens1\n",
    "accuracies['RandomForest'] = acc_ens2\n",
    "accuracies['GradientBoost'] = acc_ens3\n",
    "accuracies['DecisionTree'] = acc_tree\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(ens1)\n",
    "print(ens2)\n",
    "print(ens3)\n",
    "print(tree)\n",
    "for name,score in f_measures.items():\n",
    "    print(\"Classifier: {} -  F1 Weighted: {}\".format(name,round(score,4)))\n",
    "for name,score in accuracies.items():\n",
    "    print(\"Classifier: {} -  BalancedAccuracy: {}\".format(name,round(score,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU9POFftXMmX"
   },
   "source": [
    "Gradient Boost is the most accurate.\n",
    "\n",
    "| Classifier     | F1 Score | Accuracy |\n",
    "|----------------|----------|----------|\n",
    "| Bagging        | 0.8606   | 0.8583   |\n",
    "| Random Forest  | 0.8549   | 0.8524   |\n",
    "| Gradient Boost | 0.8741   | 0.8740   |\n",
    "| Decision Tree  | 0.7534   | 0.7584   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkJeuV1FXMmX"
   },
   "source": [
    "### 1.3 Question\n",
    "\n",
    "Increasing the number of estimators in a bagging classifier can drastically increase the training time of a classifier. Is there any solution to this problem? Can the same solution be applied to boosting classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApNEPcWEXMmY"
   },
   "source": [
    "Increasing the number of estimators in a bagging classifier will indeed increase the training time of classifier, as each estimator is trained seperately. The solution to this problem is the well-known **parallelization**. To do this we utilize multiple processors or cores on a machine, distributing the training process across them. The n_jobs parameter in scikit-learn's bagging classifiers actually specify the number of jobs to run parallel. So, we set n_jobs=-1 to use all the cores of our machine for running our tests. Of course, the processing time depends on our machine.\n",
    "\n",
    "In the case of boosting classifiers the solution of parallelization is not as helpful as in bagging. Boosting classifiers are sequential algorithms, meaning each estimator is trained sequentially and each subsequent estimator focuses on improving the mistakes made by the previous estimators. So, one approach to speed up the training process here is to use a subset of the data for each iteration rather than the entire dataset. By using smaller subsets, the training time can be reduced while still achieving good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgvsCbUGXMmY"
   },
   "source": [
    "## 2.0 Creating the best classifier ##\n",
    "In the second part of this assignment, we will try to train the best classifier, as well as to evaluate it using stratified cross valdiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6daX2mRXMmZ"
   },
   "source": [
    "### 2.1 Good Performing Ensemble\n",
    "\n",
    "In this part of the assignment you are asked to train a good performing ensemble, that is able to be used in a production environment! Describe the process you followed to achieve this result. How did you choose your classifier and your parameters and why. Report the f-measure (weighted) & balanced accuracy, using 10-fold stratified cross validation, of your final classifier. Can you achieve a balanced accuracy over 88%, while keeping the training time low? (Tip 1: You can even use a model from the previous parts, but you are advised to test additional configurations, and ensemble architectures, Tip 2: If you try a lot of models/ensembles/configurations or even grid searches, in your answer leave only the classifier you selected as the best!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00xAQ0HfXMmZ"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set one\n",
    "ens1 = SVC(C=10, gamma=0.0001, probability = False , random_state=RANDOM_STATE)\n",
    "ens2 = SVC(C=1, gamma=0.01, probability = False , random_state=RANDOM_STATE)\n",
    "ens3 = KNeighborsClassifier(n_neighbors=8, weights='distance' )\n",
    "ens4 = KNeighborsClassifier(n_neighbors=15, weights='distance' )\n",
    "ens5 = DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=50)\n",
    "ens6 = DecisionTreeClassifier(criterion='gini', max_depth=8, min_samples_leaf=5)\n",
    "\n",
    "classifiers = [('svm1', ens1), ('svm2', ens2), ('knn1', ens3), ('knn2', ens4), ('dt1', ens5), ('dt2', ens6)]\n",
    "\n",
    "# Set two\n",
    "#ens1 = RandomForestClassifier(criterion='gini', max_depth=8, max_features='auto', n_estimators=500, random_state=RANDOM_STATE)\n",
    "#ens2 = KNeighborsClassifier(n_neighbors=8, weights='distance')\n",
    "#ens3 = KNeighborsClassifier(n_neighbors=15)\n",
    "#ens4 = SVC(C= 0.1, gamma=1, kernel='poly', probability = False, random_state=RANDOM_STATE)\n",
    "#ens5 = SVC(C=10, gamma=0.0001, probability = False, random_state=RANDOM_STATE)\n",
    "\n",
    "#classifiers = [('rf', ens1), ('knn1', ens2), ('knn2', ens3), ('svm1', ens4), ('svm2', ens5)]\n",
    "\n",
    "# Set three\n",
    "#ens1 = KNeighborsClassifier(n_neighbors=8, weights='distance')\n",
    "#ens2 = KNeighborsClassifier(n_neighbors=15)\n",
    "#ens3 = SVC(C= 0.1, gamma=1, kernel='poly', probability = False ,random_state=RANDOM_STATE)\n",
    "#ens4 = SVC(C=10, gamma=0.0001, probability = False ,random_state=RANDOM_STATE)\n",
    "#ens5 = RandomForestClassifier(criterion='gini', max_depth=8, max_features='auto', n_estimators=500, random_state=RANDOM_STATE)\n",
    "#ens6 = GradientBoostingClassifier(learning_rate=0.1, max_depth=5, n_estimators=100, random_state=RANDOM_STATE)\n",
    "\n",
    "#classifiers = [('knn1',ens1),('knn2',ens2),('svm1',ens3),('svm2',ens4),('rf',ens5),('gb',ens6)]\n",
    "\n",
    "best_cls = StackingClassifier(classifiers, cv=10, n_jobs=1)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "scores_stacking = cross_validate(best_cls, X, y, scoring=('accuracy', 'f1'), cv=cv, verbose=2, n_jobs=-1)\n",
    "\n",
    "best_fmeasure = np.mean(scores_stacking['test_f1'])\n",
    "best_accuracy = np.mean(scores_stacking['test_accuracy'])\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Classifier:\")\n",
    "print(best_cls)\n",
    "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(best_fmeasure, best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnAp-d2DXMmf"
   },
   "source": [
    "LEAVE HERE ANY COMMENTS ABOUT YOUR CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_DOxFfoTUDS"
   },
   "source": [
    "As in the first sextion of the assignment, various random combinations were tested.\n",
    "\n",
    "| Set | F1 Score | Accuracy | Time |\n",
    "|-----|----------|----------|------|\n",
    "| 1   | 0.91364  | 0.91375  | 61.8 |\n",
    "| 2   | 0.91280  | 0.91286  | 67.8 |\n",
    "| 3   |    -     |    -     | 201+ |"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "I explored different sets of classifiers, including SVM, KNN, Decision Trees, Random Forest and Gradient Boosting. Each set contained different variations of these classifiers with various parameter settings. I aimed to capture different characteristics of the data and leverage their strengths for ensemble learning. In this way I identify the optimal combination that maximizes the performance metrics.\n",
    "\n",
    "To assess the performance of each ensemble configuration, I used 10-fold stratified cross-validation as needed. This was done because it ensures that the dataset is divided into balanced folds while preserving the distribution of class labels.\n",
    "\n",
    "I used the StackingClassifier, which combines the predictions of multiple base classifiers using a meta-classifier.\n",
    "\n",
    "Finally, to compare the models I focused on the f-measure (weighted) and balanced accuracy metrics."
   ],
   "metadata": {
    "id": "DOnoC5g7jerz"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnos1uqzXMma"
   },
   "source": [
    "### 2.2 Question\n",
    " What other ensemble architectures you tried, and why you did not choose them as your final classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5dAfbTfXMmb"
   },
   "source": [
    "During the experimentation process, I explored several ensemble architectures in the StackingClassifier. I need to refer the set that I used RandomForestClassifier along with GradientBoostingClassifier. This set has significantly longer training time, so in addition with the impressive results the other sets have, I decided to reject it. Speaking for the other two sets, they have approximately the same results, but the first is a little faster, so I choose this over the second. I was expecting these results as the main difference is that  I used DecisionTreeClassifier instead of RandomForest. They are too far away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI1yb95A8r3k"
   },
   "source": [
    "### 2.3 Setup the Final Classifier\n",
    "Finally, in this last cell, set the cls variable to either the best model as occured by the stratified cross_validation, or choose to retrain your classifier in the whole dataset (X, y). There is no correct answer, but try to explain your choice. Then, save your model using pickle and upload it with your submission to e-learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYNkmiUOXMmh"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "cls = best_cls\n",
    "cls.fit(X, y)\n",
    "# save with pickle\n",
    "file_name = \"final_model.pkl\"\n",
    "pickle.dump(cls, open(file_name, \"wb\"))\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "# load\n",
    "cls = pickle.load(open(file_name, \"rb\"))\n",
    "\n",
    "test_set = pd.read_csv(\"test_set_noclass.csv\")\n",
    "predictions = cls.predict(test_set)\n",
    "\n",
    "# We are going to run the following code\n",
    "if False:\n",
    "  from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "  final_test_set = pd.read_csv('test_set.csv')\n",
    "  ground_truth = final_test_set['CLASS']\n",
    "  print(\"Balanced Accuracy: {}\".format(balanced_accuracy_score(predictions, ground_truth)))\n",
    "  print(\"F1 Weighted-Score: {}\".format(f1_score(predictions, ground_truth, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pB4bTSj4Bvj"
   },
   "source": [
    "Both metrics should aim above 82%! This is going to be tested by us! Make sure your cross validation or your retrained model achieves high balanced accuracy and f1_score (based on 2.1) (more than 88%) as it should achieve at least 82% in our unknown test set!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osJK4OGy9J9f"
   },
   "source": [
    "Please provide your feedback regarding this project! Did you enjoy it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpFilLbT9Y03"
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "It was very interesting to explore different classifiers, ensemble architectures and parameter configurations to find the optimal model. This project allowed me to gain practical experience and improve my skills in machine learning. Overall, it was a rewarding and enjoyable project!"
   ],
   "metadata": {
    "id": "TX7QOy8JRFQI"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
